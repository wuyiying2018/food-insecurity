---
title: "data analysis"
author: "Yiying Wu"
date: "2024-02-20"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R packages
```{r,warning=FALSE,message=FALSE}
# INSTALL PACKAGES
packages <- c("tidyverse", "knitr", "haven","gtsummary",
              "survey", "mice","jtools","surveyCV",
              "rpms","pROC")

# Install missing packages
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages], dependencies = TRUE)
}

# Load packages invisibly
invisible(lapply(packages, library, character.only = TRUE))

# # Remove variables associated with package installation
# rm(packages, installed_packages)
```

## data preparation
```{r,warning=FALSE,message=FALSE}
# input demo data
dat_demo<-read_xpt("./data/P_DEMO.XPT")%>%
  janitor::clean_names()

# input food insecurity data
dat_fsq<-read_xpt("./data/P_FSQ.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,fsdad)

# input bmi data
dat_bmi<-read_xpt("./data/P_BMX.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,bmxbmi)

#  chronic diseases
## input hbp data
dat_hbp<-read_xpt("./data/P_BPQ.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,bpq020)

## input diabetes data
dat_diabetes<-read_xpt("./data/P_DIQ.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,diq010)

## input ckd data
dat_ckd<-read_xpt("./data/P_KIQ_U.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,kiq022)

# input insurance data
dat_insr<-read_xpt("./data/P_HIQ.XPT")%>%
  janitor::clean_names()%>%
  select(seqn,hiq011)

# combine datasets
dat <- dat_demo %>% left_join(dat_fsq, by = "seqn")
dat <- dat %>% left_join(dat_bmi, by="seqn")
dat <- dat %>% left_join(dat_hbp, by="seqn")
dat <- dat %>% left_join(dat_diabetes, by="seqn")
dat <- dat %>% left_join(dat_ckd, by="seqn")
dat <- dat %>% left_join(dat_insr, by="seqn")
```

## data cleaning

**selecting variabes**
```{r}
dat<-dat%>%
  select(
    # Survey variables 
    seqn, sdmvpsu,sdmvstra,wtmecprp,
    
    # outcome
    food_security=fsdad,
    
    # predictors
    gender=riagendr, age=ridageyr,
    race=ridreth3,country_of_birth=dmdborn4,bmi=bmxbmi,
    education=dmdeduc2,marital_status=dmdmartz, poverty=indfmpir,
    hbp=bpq020, diabetes=diq010,ckd=kiq022,insurance=hiq011)
```

**identify missing data**
```{r}
dat <-dat %>% 
  mutate(
    # demo
    ## education
    education=ifelse(education %in% c(7,9),NA,education),
    ## marital_status
    marital_status=ifelse(marital_status %in% c(77,99),NA,marital_status),
    ## country_of_birth
    country_of_birth=ifelse(country_of_birth %in% c(77,99),NA,country_of_birth),
    
    # chronic disease
    ## hbp
    hbp=ifelse(hbp==9,NA,hbp),
    ## diabetes
    diabetes=ifelse(diabetes==9,NA,diabetes),
    ## ckd
    ckd=ifelse(ckd==9,NA,ckd),
    
    #insurance
    insurance=ifelse(insurance %in% c(7,9),NA,insurance)
  )
```


**recode categorical data**
```{r}
dat <-dat %>% 
  mutate(
    # outcome variable
    ## adult food security, 1=food security, 0=food insecurity
    food_security =ifelse(food_security==1,1,ifelse(food_security %in% c(2,3,4),0,NA)),
    
    # Demographics variables
    ## gender
    female=ifelse(gender==2,1,ifelse(gender==1,0,NA)),
    ## race
    race=relevel(as.factor(race), ref ="1"),
    ## country_of_birth
    country_of_birth=ifelse(country_of_birth==2,1,ifelse(country_of_birth==1,0,NA)),
    ## education
    education=relevel(as.factor(education), ref ="1"),
    ## marital_status
    marital_status=relevel(as.factor(marital_status), ref ="1"),
    
    # chronic disease
    ## hbp
    hbp=ifelse(hbp==1,1,ifelse(hbp==2,0,NA)),
    ## diabetes
    diabetes=ifelse(diabetes==1,1,ifelse(diabetes %in% c(2,3),0,NA)),
    ## ckd
    ckd=ifelse(ckd==1,1,ifelse(ckd==2,0,NA)),
    
    #insurance
    insurance=ifelse(insurance==1,1,ifelse(insurance==2,0,NA))
  )
```

**combine categories**
```{r}
dat<-dat%>%
  mutate(
    # Demographics variables
    ## race
    
  )
```


**summary table**
```{r}
dat %>% 
  filter(age>=20)%>%
  select(everything()) %>% 
  tbl_summary() %>% 
  bold_labels()
```

**save the clean dataset**
```{r}
# save
write.csv(dat, "./result_files/dat.csv")
```


## Define survey design 
### Define survey design for overall dataset
```{r}
svy <- svydesign(data=dat, id=~sdmvpsu, strata=~sdmvstra
                          , weights=~wtmecprp, nest=TRUE)
```

```{r}
imputation.svy<-subset(svy,age >= 20)
```


## Doing Imputation and logistic regression at the Same Time
```{r}
#create five imputations. The imputations object contains all five
#complete datasets.
imputations <- mice(dat, 5, printFlag=FALSE)

lm_svy_mi <- function(formula, design, imputations) {
  
  #setting up null objects allows us to easily add results
  #later
  b <- se <- R2MF <- R2CU <-NULL
  aic <- NULL
  mean.aic <- NULL
  # AUC <- mean.AUC <-NULL
  
  #now loop through our imputations and run the model
  for(i in 1:imputations$m) {
    #grab the complete dataset
    imputation <- complete(imputations, i)
    
    #run the model
    model <- svyglm(formula, design=design,family=quasibinomial)
    #collect the results
    b <- cbind(b, coef(model))
    se <- cbind(se, summary(model)$coef[,2])
    
    summ_model <- summ(model)
      
    # # McFadden's R-squared
    R2MF <- attr(summ_model, which = "rsqmc")
    
    # # CRagg-Uhler R-squared
    R2CU <- attr(summ_model, which = "rsq")
    
    # AIC
    aic <- c(aic,(-2) * logLik(model) + 2 * length(coef(model)))
    
    # # Logistic Regression AUC calculation
    #predictions <- predict(model, type = "response")
    #ROC_res <- roc(imputation.svy$variables$bp_uncontrolled_140_90, predictions)  # Replace with dependent variable
    #AUC <- c(AUC, auc(ROC_res))
    
  }
  
  #now pool the results
  b.pool <- apply(b, 1, mean)
  between.var <- apply(b, 1, var)
  within.var <- apply(se^2, 1, mean)
  se.pool <- sqrt(within.var+between.var+between.var/imputations$m) 
  lower.ci <- b.pool - 1.96 * se.pool  # Lower bound of 95% CI
  upper.ci <- b.pool + 1.96 * se.pool  # Upper bound of 95% CI
  t.pool <- b.pool/se.pool 
  pvalue.pool <- (1-pnorm(abs(t.pool)))*2 
  coefficients <- data.frame(b.pool, se.pool, lower.ci, upper.ci, t.pool, pvalue.pool)
  
  #we can also grap n and p from the last model since 
  #they should be the same across all iterations
  n <- nobs(model)
  p <- length(model$coefficients)-1
  mean.R2MF <- mean(R2MF)
  mean.R2CU <- mean(R2CU)
  mean.aic <- mean(aic)
  #mean.AUC <- mean(AUC)
  
  #return everything in a list
  return(list(coef=coefficients,
              n=n,
              R2MF = mean.R2MF,
              R2CU = mean.R2CU,
              aic = mean.aic
              )
         )
}
```


```{r}
#now lets try the model out
model1 <- lm_svy_mi(food_security~gender+age+
    race+country_of_birth+bmi+
    education+marital_status+ poverty+
    hbp+ diabetes+ckd+insurance, imputation.svy,imputations)

model1
```

save the result
```{r}
## create result dataframe
res_df<-function(model){
    coef.names = rownames(model$coef)
    OR = exp(model$coef$b.pool)
    ci.low = exp(model$coef$lower.ci)
    ci.up = exp(model$coef$upper.ci)
    p_value=model$coef$pvalue.pool
    res<-data_frame(coef.names,OR,ci.low,ci.up,p_value)
    return(res)
}
res_m1<-res_df(model1)

# save res
write.csv(res_m1, "./result_files/res_m1.csv")
```


## for the machine learning model

Some algorithms can handle missing data internally. For instance, tree-based methods like Random Forests can work with missing values. Skip the imputation part and directly go to the modeling part.

The function folds.svy() generates design-based fold IDs for K-fold CV, using any specified strata and clusters.
Briefly: For a stratified sample, each fold will contain data from each stratum. For a cluster sample, a given cluster's rows will all be assigned to the same fold. (https://onlinelibrary.wiley.com/doi/10.1002/sta4.454)

plan to use the `surveyCV` package

https://github.com/ColbyStatSvyRsch/surveyCV

https://stats.stackexchange.com/questions/238141/two-worlds-collide-using-ml-for-complex-survey-data

https://cran.r-project.org/web/packages/surveyCV/index.html

```{r}
# Generate fold IDs that account for clustering in the survey design
set.seed(100)
nfolds <- 3
dat_subset <- dat[which(dat$age >= 20), ]
dat_subset <- as.data.frame(dat_subset)

dat_subset<-na.omit(dat_subset) 
num_clusters <- length(unique(dat_subset$sdmvpsu))
nfolds <- min(nfolds, num_clusters)
dat_subset$.foldID <- folds.svy(dat_subset, nfolds = nfolds,  clusterID = "sdmvpsu")

# Use CV to tune the bin_size parameter of rpms_forest()
bin_sizes <- c(10, 20, 50, 100, 250, 500)

# model selection based on MSE
SSEs <- rep(0, length(bin_sizes))
for(ff in 1:nfolds) {
  train <- subset(dat_subset, .foldID != ff)
  test  <- subset(dat_subset, .foldID == ff)
  for(bb in 1:length(bin_sizes)) {
    rf <- rpms_forest(food_security~gender+age+
    race+country_of_birth+bmi+
    education+marital_status+ poverty+
    hbp+ diabetes+ckd+insurance, 
                      data = train,
                      weights = ~wtmecprp, strata = ~sdmvstra,
                      clusters = ~sdmvpsu,
                      bin_size = bin_sizes[bb], f_size = 50)
    yhat <- predict(rf, newdata = test)
    res2 <- (yhat - test$food_security)^2
    # Sum up weighted SSEs, not MSEs yet,
    # b/c cluster sizes may differ across folds and b/c of survey weights
    SSEs[bb] <- SSEs[bb] + sum(res2 * test$wtmecprp)
  }
}
# Divide entire weighted sum by the sum of weights
MSEs <- SSEs / sum(dat_subset$wtmecprp)
# Show results
cbind(bin_sizes, MSEs)
```
Use AUC instead of MSE:
```{r}
AUCs <- rep(0, length(bin_sizes))
for(ff in 1:nfolds) {
  train <- subset(dat_subset, .foldID != ff)
  test  <- subset(dat_subset, .foldID == ff)
  for(bb in 1:length(bin_sizes)) {
    rf <- rpms_forest(food_security~gender+age+
    race+country_of_birth+bmi+
    education+marital_status+ poverty+
    hbp+ diabetes+ckd+insurance, 
                      data = train,
                      weights = ~wtmecprp, strata = ~sdmvstra,
                      clusters = ~sdmvpsu,
                      bin_size = bin_sizes[bb], f_size = 50)
    yhat <- predict(rf, newdata = test, type = "response") # Ensure predictions are on the scale of probabilities
    # Calculate AUC
    roc_obj <- roc(test$food_security, yhat, weights = test$wtmecprp, quiet = TRUE)
    AUCs[bb] <- AUCs[bb] + auc(roc_obj)
  }
}
# Average AUCs over folds
AUCs <- AUCs / nfolds
# Show results
cbind(bin_sizes, AUCs)
```
we can select $bin\_sizes=20$ and get the highest $AUC=0.8401272$

ROC curve
```{r}
train <- subset(dat_subset, .foldID != 1)
test  <- subset(dat_subset, .foldID == 1)
rf <- rpms_forest(food_security~gender+age+
    race+country_of_birth+bmi+
    education+marital_status+ poverty+
    hbp+ diabetes+ckd+insurance, 
                      data = train,
                      weights = ~wtmecprp, strata = ~sdmvstra,
                      clusters = ~sdmvpsu,
                      bin_size = 20, f_size = 50)
yhat <- predict(rf, newdata = test, type = "response") # Ensure predictions are on the scale of probabilities
# Calculate AUC
roc_obj <- roc(test$food_security, yhat, weights = test$wtmecprp, quiet = TRUE)

# Plotting the ROC curve
plot(roc_obj, main = "ROC Curve", col = "#1c61b6", lwd = 2)

```




rpms package

https://cran.r-project.org/web/packages/rpms/rpms.pdf